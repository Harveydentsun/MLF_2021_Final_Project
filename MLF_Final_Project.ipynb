{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLF Final Project:\n",
    "\n",
    "$$\\textbf{Quantitative Trading via Machine Learning in the\n",
    "Chinese Stock Market}$$\n",
    "\n",
    "**Author:** Bo Sun, Xinran Guo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "\n",
    "- [Introduction](#Introduction) \n",
    "- [Part I: Data Collection](#Part-I:-Data-Collection)  \n",
    "- [Part II: Data Processing](#Part-II:-Data-Processing)\n",
    "- [Part III: Baseline Model](#Part-III:-Baseline-Model)\n",
    "- [Part IV: Feature Engineering](#Part-IV:-Feature-Engineering)  \n",
    "- [Part V: Neural Network Architecture](#Part-V:-Neural-Network-Architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This project comes from the inspiration of [this report](华泰人工智能系列三十二：alphanet：因子挖掘神经网络_2020-06-15_华泰证券.pdf).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multi-dimensional data on equity trading, quantitative traders have troubles finding the dominating factors for investment decision. Two-dimensional Convolutional Neural Network (2d-CNN) is able to extract features from data matrix. Therefore, 2d-CNN seems to be a feasible model to find investment factors. In this project, we intend to carry out and evaluate this strategy using Chinese A-share stocks. After specifying model structure (see figure 2), we train our model with historical stock data and conduct backtesting on rolling basis (see figure 1).\n",
    "\n",
    "<img src=\"https://z3.ax1x.com/2021/06/22/RezGjA.png\" style=\"\" width=\"500\">\n",
    "\n",
    "<img src=\"https://z3.ax1x.com/2021/06/22/Rez534.png\" style=\"\" width=\"600\">\n",
    "\n",
    "where BN represents Batch Normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "import os\n",
    "import configparser\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our data collection process. Since PHBS has a Oracle database for A share stock price, our goal is to get data from this database. Then:\n",
    "\n",
    "- First we read from database.ini containing info of the database and use keys.\n",
    "- Second we write queries to read data from Oracle database month by month (since there is a limit for query data size)\n",
    "- Third we concatenate monthly data and save it as a parquet file.\n",
    "\n",
    "Unfortunately the database is only available in the PHBS builing, so we put our code here (they are only supposed to work within intranet) and save the data as a parquet file. Then everybody should be able to load the data from parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load database.ini to get configuration to connect Oracle database\n",
    "def read_db_config(ini_file='database.ini', section='WIND'):\n",
    "    \"\"\"\n",
    "    read database.ini\n",
    "    \"\"\"  \n",
    "    if not os.path.exists(ini_file):\n",
    "        raise IOError('File not exist[%s]' %config_file)\n",
    "        \n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(ini_file, encoding='utf-8')  \n",
    "    db_config = {}\n",
    "    if section in config.sections():\n",
    "        db_config = dict(config._sections[section])\n",
    "    else:\n",
    "        print('Section not exist：' + section)\n",
    "                \n",
    "    return db_config\n",
    "\n",
    "# get configuration\n",
    "config = read_db_config()\n",
    "# create connection to database\n",
    "eng = sa.create_engine(('{dbtype}://{user}:{password}@{host}:{port}/'\n",
    "                   '{sid}').format(**config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load market data from Filesync database\n",
    "marketdata = pd.DataFrame()\n",
    "\n",
    "# Read in a monthly frequency\n",
    "datearr = pd.date_range('2009-12-31','2020-12-31',freq='M')\n",
    "\n",
    "for i in tqdm(range(len(datearr)-1)):\n",
    "    # begin date and end date\n",
    "    lastmonthday = datearr[i].strftime(\"%Y%m%d\")\n",
    "    thismonthday = datearr[i+1].strftime(\"%Y%m%d\")\n",
    "    # query 1: price info\n",
    "    query1 = \"\"\"\n",
    "        SELECT \n",
    "        S_INFO_WINDCODE,\n",
    "        TRADE_DT,\n",
    "        S_DQ_OPEN,\n",
    "        S_DQ_HIGH，\n",
    "        S_DQ_LOW，\n",
    "        S_DQ_CLOSE，\n",
    "        S_DQ_PCTCHANGE，\n",
    "        S_DQ_VOLUME，\n",
    "        S_DQ_AMOUNT，\n",
    "        S_DQ_AVGPRICE，\n",
    "        S_DQ_ADJFACTOR\n",
    "        FROM FILESYNC.AShareEODPrices where\n",
    "        TRADE_DT > '%s' and TRADE_DT <= '%s'\n",
    "        \"\"\" % (lastmonthday,thismonthday)\n",
    "    data1 = pd.read_sql(query1,eng)\n",
    "    # query 2: derivative info\n",
    "    query2 = \"\"\"\n",
    "        SELECT \n",
    "        S_INFO_WINDCODE,\n",
    "        TRADE_DT,\n",
    "        S_DQ_TURN,\n",
    "        S_DQ_FREETURNOVER,\n",
    "        UP_DOWN_LIMIT_STATUS\n",
    "        FROM FILESYNC.AShareEODDerivativeIndicator where\n",
    "        TRADE_DT > '%s' and TRADE_DT <= '%s'\n",
    "        \"\"\" % (lastmonthday,thismonthday)\n",
    "    data2 = pd.read_sql(query2,eng)\n",
    "    # merge together\n",
    "    data1 = pd.merge(data1,data2,how='left',on=['s_info_windcode','trade_dt'])\n",
    "    marketdata = pd.concat([marketdata,data1])\n",
    "    # sleep for 5 seconds to release database\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need some extra data.\n",
    "\n",
    "First is the ST stocks, where ST stands for \"Special Treatment\".The Shanghai and Shenzhen Stock Exchange conduct special treatment on the stock transactions of listed companies with abnormal financial conditions or other conditions, and prefix them with \"ST\" in front of the abbreviation, so such stocks are called ST stocks.\n",
    "\n",
    "We will exclude ST stocks from our portfolio because they are highly illiquid and facing great delisting risks, so we need to read them from database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_info_windcode</th>\n",
       "      <th>s_type_st</th>\n",
       "      <th>entry_dt</th>\n",
       "      <th>remove_dt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600421.SH</td>\n",
       "      <td>S</td>\n",
       "      <td>20180111</td>\n",
       "      <td>20990101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002604.SZ</td>\n",
       "      <td>S</td>\n",
       "      <td>20180119</td>\n",
       "      <td>20990101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000410.SZ</td>\n",
       "      <td>S</td>\n",
       "      <td>20170503</td>\n",
       "      <td>20180301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002188.SZ</td>\n",
       "      <td>S</td>\n",
       "      <td>20180208</td>\n",
       "      <td>20990101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002427.SZ</td>\n",
       "      <td>S</td>\n",
       "      <td>20180208</td>\n",
       "      <td>20990101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  s_info_windcode s_type_st  entry_dt remove_dt\n",
       "0       600421.SH         S  20180111  20990101\n",
       "1       002604.SZ         S  20180119  20990101\n",
       "2       000410.SZ         S  20170503  20180301\n",
       "3       002188.SZ         S  20180208  20990101\n",
       "4       002427.SZ         S  20180208  20990101"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get ST，*ST stock\n",
    "query_st = \"\"\"\n",
    "    SELECT \n",
    "    S_INFO_WINDCODE,\n",
    "    S_TYPE_ST,\n",
    "    ENTRY_DT,\n",
    "    REMOVE_DT\n",
    "    FROM FILESYNC.AShareST\n",
    "    \"\"\"\n",
    "stdata = pd.read_sql(query_st,eng)\n",
    "# set current ST,*ST stock remove date to a default date\n",
    "stdata.remove_dt = stdata.remove_dt.fillna('20990101')\n",
    "stdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we also need information on the listing and delisting date of stocks.\n",
    "\n",
    "China’s A-shares have a price limit system, and newly listed stocks will have consecutive up-limits for a period of time and cannot be traded.\n",
    "\n",
    "Based on the above reason, we also exclude stocks that have been listed for less than 120 days from our portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_info_windcode</th>\n",
       "      <th>s_info_listdate</th>\n",
       "      <th>s_info_delistdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300547.SZ</td>\n",
       "      <td>20160930</td>\n",
       "      <td>20990101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>603160.SH</td>\n",
       "      <td>20161017</td>\n",
       "      <td>20990101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>603569.SH</td>\n",
       "      <td>20160810</td>\n",
       "      <td>20990101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002819.SZ</td>\n",
       "      <td>20161111</td>\n",
       "      <td>20990101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300539.SZ</td>\n",
       "      <td>20160830</td>\n",
       "      <td>20990101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  s_info_windcode s_info_listdate s_info_delistdate\n",
       "0       300547.SZ        20160930          20990101\n",
       "1       603160.SH        20161017          20990101\n",
       "2       603569.SH        20160810          20990101\n",
       "3       002819.SZ        20161111          20990101\n",
       "4       300539.SZ        20160830          20990101"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get stock listdate and delistdate\n",
    "query_listdate = \"\"\"\n",
    "    SELECT \n",
    "    S_INFO_WINDCODE,\n",
    "    S_INFO_LISTDATE,\n",
    "    S_INFO_DELISTDATE\n",
    "    FROM FILESYNC.AShareDescription\n",
    "    \"\"\" \n",
    "listdata = pd.read_sql(query_listdate,eng)\n",
    "# drop stocks that have not listed\n",
    "listdata = listdata.dropna(subset=['s_info_listdate'])\n",
    "# set current stock delistdate to a default date\n",
    "listdata.s_info_delistdate = listdata.s_info_delistdate.fillna('20990101')\n",
    "listdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do data integration. There are 6 steps:\n",
    "1. merge all data into one single DataFrame\n",
    "2. create a \"isst\" column indicating whether a stock is in Special Treatment\n",
    "3. create a \"istrade\" column indicating whether a stock is traded on that day\n",
    "4. create a \"isnew\" column indicating whether a stock has been traded for at least 120 days\n",
    "5. drop additional columns ,convert date string to datetime type and fill nan columns\n",
    "6. save the data as a parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge marketdata and listdate\n",
    "data = pd.merge(marketdata,listdata,on='s_info_windcode',how='left')\n",
    "\n",
    "# further merge with ST data\n",
    "data = pd.merge(data,stdata,on='s_info_windcode',how='left')\n",
    "\n",
    "# add column isst: whether a stock is in ST or *ST\n",
    "data.entry_dt = data.entry_dt.fillna('20990101')\n",
    "data.remove_dt = data.remove_dt.fillna('20000101')\n",
    "data['isst'] = data.apply(lambda x:1 if (x.trade_dt>=x.entry_dt)&(x.trade_dt<=x.remove_dt) else 0,axis=1)\n",
    "\n",
    "# drop additional columns\n",
    "data = data.drop(columns=['s_info_delistdate','s_type_st','entry_dt','remove_dt'])\n",
    "\n",
    "# rename columns to a simple version\n",
    "data.columns = ['stockid','date','open','high','low','close','pct','vol','amount','vwap','adjfactor','turnover','freeturn',\n",
    "                'limit','listdate','isst']\n",
    "\n",
    "# fill nan columns\n",
    "data.limit = data.limit.fillna(0)\n",
    "\n",
    "# convert date string to datetime\n",
    "data.date = pd.to_datetime(data.date)\n",
    "data.listdate = pd.to_datetime(data.listdate)\n",
    "\n",
    "# add column istrade : whether a stock is trading on that day\n",
    "data['istrade'] = data.amount.apply(lambda x:1 if x>0 else 0)\n",
    "\n",
    "# add column isnew : whether a stock has been traded for at least 120 days\n",
    "data['isnew'] = 0\n",
    "data.loc[data.date - data.listdate <= pd.Timedelta('120 days'),'isnew']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data as a parquet file\n",
    "data.to_parquet('data.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to specify a market index as our benchmark. \n",
    "\n",
    "We choose The Shanghai Securities Composite Index (000001.SH) as our benchmark. Its sample stocks are all stocks listed on the Shanghai Stock Exchange, including A shares and B shares, reflecting the changes in the prices of listed stocks on the Shanghai Stock Exchange. It was officially released on July 15, 1991.\n",
    "\n",
    "we also read the index data from PHBS database and save it as 'marketindex.parquet' file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get market index data\n",
    "query_index = \"\"\"\n",
    "    SELECT \n",
    "    TRADE_DT,\n",
    "    S_DQ_CLOSE\n",
    "    FROM FILESYNC.AIndexEODPrices\n",
    "    WHERE S_INFO_WINDCODE = '000001.SH'\n",
    "    AND TRADE_DT>='20100101' AND TRADE_DT<='20201231'\n",
    "    \"\"\" \n",
    "indexdata = pd.read_sql(query_index,eng)\n",
    "\n",
    "# rename columns \n",
    "indexdata.columns = ['date','close']\n",
    "\n",
    "# convert date string to datetime\n",
    "indexdata.date = pd.to_datetime(indexdata.date)\n",
    "\n",
    "# save the data as a parquet file\n",
    "indexdata.to_parquet('marketindex.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use CNN and LSTM model, we need to convert our data to \"data pictures\" that serve as training and predicting inputs. Our data pictures take the following format:\n",
    "\n",
    "**Stock universe :** All Chinese A-share main board stocks, excluding newly-listed stocks, ST and PT stocks, and all stocks that are suspended or hit price limits in the following trading day.\n",
    "\n",
    "**Time span :** Starting from 2011, we use past 1500 days data as input, among which 400 days are training period, and the remaining 100 days are validation periods.\n",
    "\n",
    "**Variables :**\n",
    "- return: daily return\n",
    "- open, high, low, close: daily open price, highest price, lowest price, and close price\n",
    "- volume: daily trading volume\n",
    "- vwap: daily volume weighted average price\n",
    "- turn: daily turnover rate\n",
    "- free_turn: daily turnover rate of free float shares\n",
    "\n",
    "**Input shape :** 9*30\n",
    "\n",
    "**Labels :** standardized returns in the next two weeks (10 days)\n",
    "\n",
    "Here is what our data pictures look like:\n",
    "<img src=\"https://z3.ax1x.com/2021/07/23/Wymq56.png\" style=\"\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from parquet file\n",
    "data = pd.read_parquet(r\"data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stockid</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>pct</th>\n",
       "      <th>vol</th>\n",
       "      <th>amount</th>\n",
       "      <th>vwap</th>\n",
       "      <th>turnover</th>\n",
       "      <th>freeturn</th>\n",
       "      <th>adjfactor</th>\n",
       "      <th>limit</th>\n",
       "      <th>listdate</th>\n",
       "      <th>isst</th>\n",
       "      <th>istrade</th>\n",
       "      <th>isnew</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.SZ</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>24.52</td>\n",
       "      <td>24.58</td>\n",
       "      <td>23.68</td>\n",
       "      <td>23.71</td>\n",
       "      <td>-2.7082</td>\n",
       "      <td>241922.76</td>\n",
       "      <td>5.802495e+05</td>\n",
       "      <td>23.9849</td>\n",
       "      <td>0.8273</td>\n",
       "      <td>0.9360</td>\n",
       "      <td>35.905536</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1991-04-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.105863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.SZ</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>10.85</td>\n",
       "      <td>10.87</td>\n",
       "      <td>10.60</td>\n",
       "      <td>10.60</td>\n",
       "      <td>-1.9426</td>\n",
       "      <td>969832.53</td>\n",
       "      <td>1.034345e+06</td>\n",
       "      <td>10.6652</td>\n",
       "      <td>1.0044</td>\n",
       "      <td>1.2067</td>\n",
       "      <td>110.804114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1991-01-29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.382315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000004.SZ</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.063862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1991-01-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.843219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000005.SZ</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>6.01</td>\n",
       "      <td>6.05</td>\n",
       "      <td>5.91</td>\n",
       "      <td>5.99</td>\n",
       "      <td>-0.4983</td>\n",
       "      <td>223582.22</td>\n",
       "      <td>1.334784e+05</td>\n",
       "      <td>5.9700</td>\n",
       "      <td>2.4469</td>\n",
       "      <td>3.0649</td>\n",
       "      <td>9.267603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1990-12-10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.239352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000006.SZ</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>11.33</td>\n",
       "      <td>11.35</td>\n",
       "      <td>11.11</td>\n",
       "      <td>11.12</td>\n",
       "      <td>-1.8535</td>\n",
       "      <td>62998.05</td>\n",
       "      <td>7.054856e+04</td>\n",
       "      <td>11.1985</td>\n",
       "      <td>1.2804</td>\n",
       "      <td>1.5873</td>\n",
       "      <td>11.023514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1992-04-27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.607098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     stockid       date   open   high    low  close     pct        vol  \\\n",
       "0  000001.SZ 2010-01-04  24.52  24.58  23.68  23.71 -2.7082  241922.76   \n",
       "1  000002.SZ 2010-01-04  10.85  10.87  10.60  10.60 -1.9426  969832.53   \n",
       "2  000004.SZ 2010-01-04  10.00  10.00  10.00  10.00  0.0000       0.00   \n",
       "3  000005.SZ 2010-01-04   6.01   6.05   5.91   5.99 -0.4983  223582.22   \n",
       "4  000006.SZ 2010-01-04  11.33  11.35  11.11  11.12 -1.8535   62998.05   \n",
       "\n",
       "         amount     vwap  turnover  freeturn   adjfactor  limit   listdate  \\\n",
       "0  5.802495e+05  23.9849    0.8273    0.9360   35.905536    0.0 1991-04-03   \n",
       "1  1.034345e+06  10.6652    1.0044    1.2067  110.804114    0.0 1991-01-29   \n",
       "2  0.000000e+00  10.0000    0.0000    0.0000    4.063862    0.0 1991-01-14   \n",
       "3  1.334784e+05   5.9700    2.4469    3.0649    9.267603    0.0 1990-12-10   \n",
       "4  7.054856e+04  11.1985    1.2804    1.5873   11.023514    0.0 1992-04-27   \n",
       "\n",
       "   isst  istrade  isnew    return  \n",
       "0   0.0        1      0 -2.105863  \n",
       "1   0.0        1      0 -1.382315  \n",
       "2   0.0        0      0 -0.843219  \n",
       "3   0.0        1      0 -0.239352  \n",
       "4   0.0        1      0 -0.607098  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate 10-days return\n",
    "data['return'] = data.groupby('stockid').apply(lambda x:(x.open.shift(-11)/x.open.shift(-1)-1).fillna(0)) \\\n",
    "                    .reset_index(level=0,drop=True)\n",
    "# standardize\n",
    "data['return'] = data.groupby('date').apply(lambda x:((x['return']-x['return'].mean())/x['return'].std()).fillna(0)) \\\n",
    "                    .reset_index(level=0,drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate_training_picture` function converts raw data into a training set.\n",
    "\n",
    "We use last 400-day trading information to train our model, given an input date t. The outputs include training data picture array and label array containing standardized return, which should have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training samples given the date\n",
    "# all stocks, one picture every 5 days for the last 400 trading days\n",
    "def generate_training_picture(data, t, gap, num):\n",
    "    factor_list = ['open', 'high', 'low', 'close', 'vwap', 'vol', 'pct', 'turnover', 'freeturn']\n",
    "    stock_list = data.stockid.unique()\n",
    "    X = []\n",
    "    Y = []\n",
    "    data = data.set_index(['stockid', 'date'])\n",
    "    for stockid in tqdm(stock_list):\n",
    "        stockdata = data.loc[(stockid, slice(None))]\n",
    "        stock_picture = stockdata[stockdata.amount > 0][factor_list].T\n",
    "\n",
    "        datearr = stock_picture.columns\n",
    "        n = len(datearr[datearr <= t])\n",
    "        if n <= 30:\n",
    "            continue\n",
    "        narr = np.arange(n - 10, max(30, n - 10 - gap*num), -gap)\n",
    "        for i in narr:\n",
    "            X.append(stock_picture.iloc[:, i - 30:i].values)\n",
    "            Y.append(stockdata.loc[datearr[i], 'return'])\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4198/4198 [01:27<00:00, 48.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the data picture array:  157882\n",
      "Length of the inputs:  157882\n"
     ]
    }
   ],
   "source": [
    "X, Y = generate_training_picture(data, pd.to_datetime('2020-12-03'),5,80)\n",
    "print ('Length of the data picture array: ',len(X))\n",
    "print ('Length of the inputs: ',len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data picture: \n",
      " [[ 1.48000000e+01  1.53000000e+01  1.52200000e+01  1.59000000e+01\n",
      "   1.60400000e+01  1.62000000e+01  1.65600000e+01  1.73000000e+01\n",
      "   1.74800000e+01  1.76400000e+01  1.79400000e+01  1.75300000e+01\n",
      "   1.82000000e+01  1.80000000e+01  1.77600000e+01  1.75400000e+01\n",
      "   1.77400000e+01  1.76500000e+01  1.77100000e+01  1.83500000e+01\n",
      "   1.83700000e+01  1.77100000e+01  1.76700000e+01  1.80000000e+01\n",
      "   1.82000000e+01  1.78100000e+01  1.74200000e+01  1.70800000e+01\n",
      "   1.73800000e+01  1.77800000e+01]\n",
      " [ 1.52700000e+01  1.55500000e+01  1.60500000e+01  1.61100000e+01\n",
      "   1.61200000e+01  1.69200000e+01  1.73700000e+01  1.81000000e+01\n",
      "   1.76000000e+01  1.80000000e+01  1.85000000e+01  1.87800000e+01\n",
      "   1.82900000e+01  1.80000000e+01  1.79000000e+01  1.79300000e+01\n",
      "   1.83600000e+01  1.80500000e+01  1.83400000e+01  1.84800000e+01\n",
      "   1.85000000e+01  1.77500000e+01  1.80000000e+01  1.85000000e+01\n",
      "   1.83000000e+01  1.79400000e+01  1.74700000e+01  1.74300000e+01\n",
      "   1.79300000e+01  1.85000000e+01]\n",
      " [ 1.48000000e+01  1.51300000e+01  1.52100000e+01  1.57700000e+01\n",
      "   1.58000000e+01  1.61500000e+01  1.65400000e+01  1.73000000e+01\n",
      "   1.72500000e+01  1.73300000e+01  1.73000000e+01  1.75300000e+01\n",
      "   1.74500000e+01  1.75000000e+01  1.72900000e+01  1.73500000e+01\n",
      "   1.76000000e+01  1.73300000e+01  1.77000000e+01  1.79600000e+01\n",
      "   1.75400000e+01  1.72200000e+01  1.75400000e+01  1.79300000e+01\n",
      "   1.76000000e+01  1.74500000e+01  1.66900000e+01  1.69000000e+01\n",
      "   1.72500000e+01  1.77500000e+01]\n",
      " [ 1.51700000e+01  1.51800000e+01  1.59000000e+01  1.60600000e+01\n",
      "   1.60300000e+01  1.65600000e+01  1.71000000e+01  1.74800000e+01\n",
      "   1.75400000e+01  1.79100000e+01  1.75600000e+01  1.81300000e+01\n",
      "   1.77000000e+01  1.77600000e+01  1.76300000e+01  1.77700000e+01\n",
      "   1.77500000e+01  1.76300000e+01  1.79600000e+01  1.83200000e+01\n",
      "   1.77000000e+01  1.76400000e+01  1.78400000e+01  1.81100000e+01\n",
      "   1.78100000e+01  1.76600000e+01  1.71800000e+01  1.73700000e+01\n",
      "   1.78300000e+01  1.84600000e+01]\n",
      " [ 1.51064000e+01  1.52927000e+01  1.57665000e+01  1.59986000e+01\n",
      "   1.59674000e+01  1.65892000e+01  1.71273000e+01  1.77140000e+01\n",
      "   1.74276000e+01  1.77094000e+01  1.76780000e+01  1.82845000e+01\n",
      "   1.77425000e+01  1.77728000e+01  1.76278000e+01  1.76947000e+01\n",
      "   1.79903000e+01  1.75821000e+01  1.80347000e+01  1.82411000e+01\n",
      "   1.78987000e+01  1.75132000e+01  1.77503000e+01  1.81589000e+01\n",
      "   1.78466000e+01  1.76784000e+01  1.69990000e+01  1.72163000e+01\n",
      "   1.76979000e+01  1.82658000e+01]\n",
      " [ 1.21706482e+06  9.00425930e+05  1.59134715e+06  9.08819480e+05\n",
      "   6.62562360e+05  1.60006232e+06  2.09561419e+06  2.01610552e+06\n",
      "   9.60071950e+05  1.24456018e+06  1.89051905e+06  1.69850168e+06\n",
      "   1.17559865e+06  1.03486504e+06  1.20582386e+06  8.46603620e+05\n",
      "   1.00780383e+06  9.68452770e+05  9.57868630e+05  1.24763640e+06\n",
      "   1.42946944e+06  8.48781530e+05  9.51424320e+05  1.02106281e+06\n",
      "   9.40130070e+05  6.77258480e+05  1.28918923e+06  7.59856930e+05\n",
      "   8.52930510e+05  1.37340072e+06]\n",
      " [ 2.50000000e+00  6.59000000e-02  4.74310000e+00  1.00630000e+00\n",
      "  -1.86800000e-01  3.30630000e+00  3.26090000e+00  2.22220000e+00\n",
      "   3.43200000e-01  2.10950000e+00 -1.95420000e+00  3.24600000e+00\n",
      "  -2.37180000e+00  3.39000000e-01 -7.32000000e-01  7.94100000e-01\n",
      "  -1.12500000e-01 -6.76100000e-01  1.87180000e+00  2.00450000e+00\n",
      "  -3.38430000e+00 -3.39000000e-01  1.13380000e+00  1.51350000e+00\n",
      "  -1.65650000e+00 -8.42200000e-01 -2.71800000e+00  1.10590000e+00\n",
      "   2.64820000e+00  3.53340000e+00]\n",
      " [ 6.27200000e-01  4.64000000e-01  8.20000000e-01  4.68300000e-01\n",
      "   3.41400000e-01  8.24500000e-01  1.07990000e+00  1.03890000e+00\n",
      "   4.94700000e-01  6.41300000e-01  9.74200000e-01  8.75300000e-01\n",
      "   6.05800000e-01  5.33300000e-01  6.21400000e-01  4.36300000e-01\n",
      "   5.19300000e-01  4.99100000e-01  4.93600000e-01  6.42900000e-01\n",
      "   7.36600000e-01  4.37400000e-01  4.90300000e-01  5.26200000e-01\n",
      "   4.84500000e-01  3.49000000e-01  6.64300000e-01  3.91600000e-01\n",
      "   4.39500000e-01  7.07700000e-01]\n",
      " [ 1.41500000e+00  1.04690000e+00  1.85020000e+00  1.05660000e+00\n",
      "   7.70300000e-01  1.86030000e+00  2.43640000e+00  2.34400000e+00\n",
      "   1.11620000e+00  1.44700000e+00  2.19800000e+00  1.97470000e+00\n",
      "   1.36680000e+00  1.20320000e+00  1.40190000e+00  9.84300000e-01\n",
      "   1.17170000e+00  1.12600000e+00  1.11370000e+00  1.45060000e+00\n",
      "   1.66200000e+00  9.86800000e-01  1.10620000e+00  1.18710000e+00\n",
      "   1.09300000e+00  7.87400000e-01  1.49890000e+00  8.83400000e-01\n",
      "   9.91700000e-01  1.59680000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Sample data picture: \\n\",X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample label: \n",
      " 0.45579502261651406\n"
     ]
    }
   ],
   "source": [
    "print (\"Sample label: \\n\",Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `generate_all_pictures` function converts all raw data into pictures and save them as **.npy file**.\n",
    "\n",
    "We train our model every 10 days. Once we have set up and trained our model, we would use it in the next trading day. So, in addition to generate prediction inputs, we need to generate stock ticker and date information that corresponds to the input label so that we can select stocks based on the model predictions.\n",
    "\n",
    "The files consists of three formats, e.g. **X_2020-01-01.npy** , **Y_2020-01-01.npy** , **stock_2020-01-01.npy** , that stores information of inputs, outputs and stock labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>`All the python code in this part is reported in data_picture.py in the attachment.`</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data pictures for all t\n",
    "def generate_all_pictures(data):\n",
    "    # calculate 10-days return\n",
    "    data['return'] = data.groupby('stockid').apply(lambda x: (x.open.shift(-11) / x.open.shift(-1) - 1).fillna(0)) \\\n",
    "        .reset_index(level=0, drop=True)\n",
    "    # standardize\n",
    "    data['return'] = data.groupby('date').apply(\n",
    "        lambda x: ((x['return'] - x['return'].mean()) / x['return'].std()).fillna(0)) \\\n",
    "        .reset_index(level=0, drop=True)\n",
    "\n",
    "    factor_list = ['open', 'high', 'low', 'close', 'vwap', 'vol', 'pct', 'turnover', 'freeturn']\n",
    "    data = data.set_index(['stockid', 'date'])\n",
    "    date_arr = data.index.get_level_values(1)\n",
    "    date_list = date_arr.unique()\n",
    "    for i, t in enumerate(tqdm(date_list)):\n",
    "        if i < 29:\n",
    "            continue\n",
    "        t_1 = date_list[i-29]\n",
    "        tdata = data[(date_arr >= t_1) & (date_arr <= t)]\n",
    "        stock_list = tdata.index.get_level_values(0).unique()\n",
    "        X = []\n",
    "        Y = []\n",
    "        asset = []\n",
    "        for stock in stock_list:\n",
    "            stock_t = tdata.loc[stock,:]\n",
    "            if stock_t.shape[0] == 30 and stock_t.isnew.max() == 0 and \\\n",
    "                    stock_t.isst.max() == 0 and stock_t.istrade.max() == 1:\n",
    "                X.append(stock_t[factor_list].T.values)\n",
    "                Y.append(stock_t.loc[t, 'return'])\n",
    "                asset.append(stock)\n",
    "        X = np.array(X)\n",
    "        Y = np.array(Y)\n",
    "        asset = np.array(asset)\n",
    "        np.save(r'pictures/X_%s.npy' % t.strftime('%Y%m%d'), X)\n",
    "        np.save(r'pictures/Y_%s.npy' % t.strftime('%Y%m%d'), Y)\n",
    "        np.save(r'pictures/stock_%s.npy' % t.strftime('%Y%m%d'), asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.57500000e+01  1.58900000e+01  1.56400000e+01  1.58900000e+01\n",
      "   1.56400000e+01  1.54700000e+01  1.55400000e+01  1.53500000e+01\n",
      "   1.53000000e+01  1.53400000e+01  1.53500000e+01  1.54700000e+01\n",
      "   1.56200000e+01  1.53600000e+01  1.53800000e+01  1.56600000e+01\n",
      "   1.58500000e+01  1.61200000e+01  1.60000000e+01  1.64300000e+01\n",
      "   1.65500000e+01  1.65500000e+01  1.66800000e+01  1.62300000e+01\n",
      "   1.64500000e+01  1.63400000e+01  1.65300000e+01  1.64600000e+01\n",
      "   1.65700000e+01  1.66500000e+01]\n",
      " [ 1.58700000e+01  1.59200000e+01  1.58400000e+01  1.58900000e+01\n",
      "   1.56400000e+01  1.55400000e+01  1.55500000e+01  1.54300000e+01\n",
      "   1.54600000e+01  1.54100000e+01  1.54800000e+01  1.57200000e+01\n",
      "   1.56200000e+01  1.53800000e+01  1.56800000e+01  1.56700000e+01\n",
      "   1.61200000e+01  1.61400000e+01  1.66300000e+01  1.66600000e+01\n",
      "   1.67400000e+01  1.66800000e+01  1.66800000e+01  1.65000000e+01\n",
      "   1.65600000e+01  1.64800000e+01  1.69300000e+01  1.66300000e+01\n",
      "   1.66300000e+01  1.69500000e+01]\n",
      " [ 1.56300000e+01  1.55500000e+01  1.55400000e+01  1.54900000e+01\n",
      "   1.53900000e+01  1.54400000e+01  1.51800000e+01  1.52300000e+01\n",
      "   1.52100000e+01  1.52100000e+01  1.53000000e+01  1.54600000e+01\n",
      "   1.53500000e+01  1.52500000e+01  1.53000000e+01  1.55300000e+01\n",
      "   1.57700000e+01  1.58700000e+01  1.59800000e+01  1.64100000e+01\n",
      "   1.64400000e+01  1.64400000e+01  1.61700000e+01  1.62300000e+01\n",
      "   1.62400000e+01  1.63200000e+01  1.64300000e+01  1.61000000e+01\n",
      "   1.63100000e+01  1.65500000e+01]\n",
      " [ 1.58600000e+01  1.55900000e+01  1.58000000e+01  1.56200000e+01\n",
      "   1.54700000e+01  1.54900000e+01  1.52900000e+01  1.53600000e+01\n",
      "   1.54500000e+01  1.53100000e+01  1.54300000e+01  1.56000000e+01\n",
      "   1.54100000e+01  1.53300000e+01  1.56600000e+01  1.56000000e+01\n",
      "   1.61200000e+01  1.61300000e+01  1.65000000e+01  1.64600000e+01\n",
      "   1.65500000e+01  1.65900000e+01  1.62400000e+01  1.64000000e+01\n",
      "   1.63000000e+01  1.64700000e+01  1.66300000e+01  1.65700000e+01\n",
      "   1.64500000e+01  1.68700000e+01]\n",
      " [ 1.57724000e+01  1.57221000e+01  1.57469000e+01  1.55967000e+01\n",
      "   1.54689000e+01  1.54822000e+01  1.53158000e+01  1.53425000e+01\n",
      "   1.53769000e+01  1.52915000e+01  1.53959000e+01  1.55683000e+01\n",
      "   1.54315000e+01  1.53020000e+01  1.55109000e+01  1.56059000e+01\n",
      "   1.59596000e+01  1.60264000e+01  1.63734000e+01  1.65302000e+01\n",
      "   1.65783000e+01  1.65695000e+01  1.63926000e+01  1.63865000e+01\n",
      "   1.63807000e+01  1.64066000e+01  1.67036000e+01  1.64094000e+01\n",
      "   1.63918000e+01  1.68027000e+01]\n",
      " [ 7.72563240e+05  7.73473540e+05  7.83257940e+05  8.15297530e+05\n",
      "   4.76169980e+05  3.78016510e+05  6.53866910e+05  5.53877380e+05\n",
      "   4.55418050e+05  5.24545270e+05  5.57084460e+05  7.12615240e+05\n",
      "   6.05992890e+05  5.56383880e+05  8.71505190e+05  4.78998820e+05\n",
      "   1.05310381e+06  7.87952340e+05  1.20310490e+06  7.97091330e+05\n",
      "   6.75536760e+05  6.44478380e+05  7.15792720e+05  4.59128420e+05\n",
      "   4.14917980e+05  3.72033860e+05  1.04257472e+06  9.76970310e+05\n",
      "   7.04442250e+05  1.53023187e+06]\n",
      " [ 6.31000000e-02 -1.70240000e+00  1.34700000e+00 -1.13920000e+00\n",
      "  -9.60300000e-01  1.29300000e-01 -1.29120000e+00  4.57800000e-01\n",
      "   5.85900000e-01 -9.06100000e-01  7.83800000e-01  1.10170000e+00\n",
      "  -1.21790000e+00 -5.19100000e-01  2.15260000e+00 -3.83100000e-01\n",
      "   3.33330000e+00  6.20000000e-02  2.29390000e+00 -2.42400000e-01\n",
      "   5.46800000e-01  2.41700000e-01 -2.10970000e+00  9.85200000e-01\n",
      "  -6.09800000e-01  1.04290000e+00  9.71500000e-01 -3.60800000e-01\n",
      "  -7.24200000e-01  2.55320000e+00]\n",
      " [ 3.98100000e-01  3.98600000e-01  4.03600000e-01  4.20100000e-01\n",
      "   2.45400000e-01  1.94800000e-01  3.36900000e-01  2.85400000e-01\n",
      "   2.34700000e-01  2.70300000e-01  2.87100000e-01  3.67200000e-01\n",
      "   3.12300000e-01  2.86700000e-01  4.49100000e-01  2.46800000e-01\n",
      "   5.42700000e-01  4.06000000e-01  6.20000000e-01  4.10800000e-01\n",
      "   3.48100000e-01  3.32100000e-01  3.68900000e-01  2.36600000e-01\n",
      "   2.13800000e-01  1.91700000e-01  5.37300000e-01  5.03400000e-01\n",
      "   3.63000000e-01  7.88500000e-01]\n",
      " [ 8.98200000e-01  8.99300000e-01  9.10600000e-01  9.47900000e-01\n",
      "   5.53600000e-01  4.39500000e-01  7.60200000e-01  6.44000000e-01\n",
      "   5.29500000e-01  6.09900000e-01  6.47700000e-01  8.28500000e-01\n",
      "   7.04600000e-01  6.46900000e-01  1.01320000e+00  5.56900000e-01\n",
      "   1.22440000e+00  9.16100000e-01  1.39880000e+00  9.26700000e-01\n",
      "   7.85400000e-01  7.49300000e-01  8.32200000e-01  5.33800000e-01\n",
      "   4.82400000e-01  4.32500000e-01  1.21210000e+00  1.13590000e+00\n",
      "   8.19000000e-01  1.77910000e+00]]\n"
     ]
    }
   ],
   "source": [
    "X_sample = np.load(r'pictures/X_%s.npy' % '20200102')\n",
    "print (X_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7516672143782834\n"
     ]
    }
   ],
   "source": [
    "Y_sample = np.load(r'pictures/Y_%s.npy' % '20200102')\n",
    "print (Y_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000001.SZ\n"
     ]
    }
   ],
   "source": [
    "stock_sample = np.load(r'pictures/stock_%s.npy' % '20200102')\n",
    "print (stock_sample[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first constructs a baseline model using NN with 2 hiden layers.\n",
    "\n",
    "- The first hidden layer consists of:\n",
    "    - 90 neurons\n",
    "    - ReLU activation function\n",
    "    - 50% dropout\n",
    "- The second hidden layer consists of:\n",
    "    - 30 neurons\n",
    "    - ReLU activation function\n",
    "    - 50% dropout\n",
    "- The output layer consists of:\n",
    "    - 1 neurons\n",
    "    - linear activation function\n",
    "    \n",
    "<b>`All the python code in this part is reported in Baseline.py in the attachment.`</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"baseline.png\" style=\"\" width=\"900\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baselineModel:\n",
    "    # baseline model\n",
    "    # Feature Extraction Layer + Dense Layer\n",
    "\n",
    "    def __init__(self, name, config, fit_config):\n",
    "        self.name = name\n",
    "        self.config = config\n",
    "        self.fit_config = fit_config\n",
    "\n",
    "        tf.random.set_seed(1)\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.Input(shape=(270,)),\n",
    "            tf.keras.layers.BatchNormalization(),  # normalize data\n",
    "\n",
    "            tf.keras.layers.Dense(units=90, activation='relu',\n",
    "                                  kernel_initializer=tf.keras.initializers.TruncatedNormal()),\n",
    "            tf.keras.layers.Dropout(rate=0.5),  # drop out 50% of the neurons\n",
    "            # tf.keras.layers.BatchNormalization(),  # normalize data\n",
    "            tf.keras.layers.Dense(units=30, activation='relu',\n",
    "                                  kernel_initializer=tf.keras.initializers.TruncatedNormal()),\n",
    "            tf.keras.layers.Dropout(rate=0.5),  # drop out 50% of the neurons\n",
    "            # tf.keras.layers.BatchNormalization(),  # normalize data\n",
    "            tf.keras.layers.Dense(units=1, kernel_initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        ])\n",
    "        opt = tf.keras.optimizers.Adam(lr=self.config['learning_rate'], clipvalue=0.5)\n",
    "        self.model.compile(loss=self.config['loss'], optimizer=opt, metrics=self.config['metrics'])\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.model.fit(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            **self.fit_config\n",
    "        )\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we test our result using this simple baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baselineResult(begt, endt):\n",
    "    config = {\n",
    "        'model_path': Path('models'),\n",
    "        'feat_num': 270,\n",
    "        'learning_rate': 0.002,\n",
    "        'loss': 'mse',\n",
    "        'metrics': 'mse',\n",
    "    }\n",
    "\n",
    "    fit_config = {\n",
    "        'batch_size': 3000,\n",
    "        'epochs': 100,\n",
    "    }\n",
    "    data = pd.read_parquet(\"data.parquet\")\n",
    "    date_list = data.date.unique()\n",
    "    beg_n = np.argmax(date_list[date_list <= pd.to_datetime(begt)]) + 1\n",
    "    end_n = np.argmax(date_list[date_list <= pd.to_datetime(endt)])\n",
    "    df_predict = pd.DataFrame(columns=['date','stock','score'])\n",
    "    for n in np.arange(beg_n, end_n, 10):\n",
    "        x_train_raw = []\n",
    "        y_train = []\n",
    "        for i in np.arange(n-1,n-201,-5):\n",
    "            t = pd.to_datetime(date_list[i]).strftime('%Y%m%d')\n",
    "            X_t = np.load(\"pictures/X_%s.npy\" % t)\n",
    "            Y_t = np.load(\"pictures/Y_%s.npy\" % t)\n",
    "            if len(x_train_raw):\n",
    "                x_train_raw = np.concatenate((x_train_raw, X_t), axis=0)\n",
    "            else:\n",
    "                x_train_raw = X_t\n",
    "            if len(y_train):\n",
    "                y_train = np.concatenate((y_train, Y_t), axis=0)\n",
    "            else:\n",
    "                y_train = Y_t\n",
    "        x_train_raw = x_train_raw.reshape(x_train_raw.shape[0], 270)\n",
    "\n",
    "        selector = baselineModel('stock_selector_on_%s' % t, config, fit_config)\n",
    "        selector.fit(x_train_raw, y_train)\n",
    "\n",
    "        predict_t = pd.to_datetime(date_list[n]).strftime('%Y%m%d')\n",
    "        x_predict = np.load(\"pictures/X_%s.npy\" % predict_t)\n",
    "        x_predict = x_predict.reshape(x_predict.shape[0], 270)\n",
    "        stock_predict = np.load(\"pictures/stock_%s.npy\" % predict_t)\n",
    "        y_predict = selector.predict(np.asarray(x_predict).astype(np.float32))\n",
    "\n",
    "        score_t = pd.DataFrame(np.transpose([stock_predict,y_predict.reshape(-1)]),columns=['stock','score'])\n",
    "        score_t['date'] = pd.to_datetime(date_list[n])\n",
    "\n",
    "        df_predict = pd.concat([df_predict,score_t])\n",
    "        print (t)\n",
    "    df_predict = df_predict.set_index(['date','stock'])\n",
    "    df_predict.to_parquet(\"predictions/%s-%s.parquet\"%(begt,endt))\n",
    "\n",
    "    return df_predict\n",
    "\n",
    "begt = '2020-01-01'\n",
    "endt = '2020-12-31'\n",
    "baselineResult(begt, endt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a bespoke backtest engine to horserace the performance of our strategies. It has 4 parts:\n",
    "\n",
    "- **Initialize functions** : set parameters and load market data\n",
    "    - we use VWAP as our trading price,\n",
    "    - market price is adjusted for stock and cash dividends\n",
    "    \n",
    "- **Selecting function** : calculate target portfolio on a given trade day\n",
    "\n",
    "     - we only select stocks that are tradable, not ST, not up-limit and not newly listed\n",
    "    \n",
    "- **Backtest function** : calculate portfolio netvalue and benchmark value\n",
    "\n",
    "- **Evaluation function and plot function** : display the result\n",
    "\n",
    "     - evaluation is displayed in a monthly basis\n",
    "     \n",
    "     - plot function plots the portfolio as well as benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackTest():\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfScore : DataFrame, containing the predicted stock return.\n",
    "    \n",
    "    begt: datetime, backtest begin date. Can be specified or empty.\n",
    "    \n",
    "    endt: datetime, backtest begin date. Can be specified or empty.\n",
    "    \n",
    "    n: int, the number of stocks selected in daily portfolio.\n",
    "    \n",
    "    fee: int, transaction fee. Default 0.2%\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, dfScore, begt=np.nan, endt=np.nan, n=30, freq=10, fee=0.002):\n",
    "        self.dfScore = dfScore\n",
    "        self.begt = begt\n",
    "        self.endt = endt\n",
    "        self.n = n\n",
    "        self.freq = freq\n",
    "        self.fee = fee\n",
    "        self._set_begin_end()\n",
    "        self._init_price_matrix()\n",
    "        self._init_index()\n",
    "\n",
    "    # Set begin date and end date\n",
    "    def _set_begin_end(self):\n",
    "        if np.isnan(self.begt):\n",
    "            self.begt = self.dfScore.index.get_level_values(0).min()\n",
    "        if np.isnan(self.endt):\n",
    "            self.endt = self.dfScore.index.get_level_values(0).max()\n",
    "            \n",
    "    # Load market data \n",
    "    def _init_price_matrix(self):\n",
    "        data = pd.read_parquet(\"data.parquet\").set_index(['date', 'stockid'])\n",
    "        data = data.loc[\n",
    "            pd.IndexSlice[self.begt:self.endt, :], ['vwap', 'adjfactor', 'isnew', 'isst', 'istrade', 'limit']]\n",
    "        data['vwap_adj'] = data.vwap * data.adjfactor\n",
    "        self.price_matrix = data['vwap_adj'].unstack()\n",
    "        self.status_matrix = data[['isnew', 'isst', 'istrade', 'limit']]\n",
    "\n",
    "    # Load index data\n",
    "    def _init_index(self):\n",
    "        indexdata = pd.read_parquet(\"marketindex.parquet\").set_index('date')\n",
    "        self.indexdata = indexdata.loc[self.begt:self.endt]\n",
    "\n",
    "    # get all market trading days\n",
    "    def gettradedate(self):\n",
    "        tradedate = self.indexdata.index\n",
    "        return tradedate[(tradedate >= self.begt) & (tradedate <= self.endt)]\n",
    "\n",
    "    # get index for a specific day\n",
    "    def getindex(self, t):\n",
    "        try:\n",
    "            indexclose = self.indexdata.loc[t, 'close']\n",
    "            base = self.indexdata.iloc[0, 0]\n",
    "        except:\n",
    "            raise TypeError('Stock Index Reading Error！')\n",
    "\n",
    "        return (indexclose / base)\n",
    "\n",
    "    # get target portfolio for a specific day\n",
    "    def gettradestock(self, t):\n",
    "        tscore = self.dfScore.loc[pd.IndexSlice[t, :]]\n",
    "        # delete unavailable stocks\n",
    "        tprice = self.status_matrix.loc[pd.IndexSlice[t, :]]\n",
    "        tprice = tprice[(tprice.istrade == 1) & (tprice.isnew == 0) & (tprice.isst == 0) & (tprice.limit != 1)]\n",
    "        tprice['score'] = tscore.score\n",
    "        tprice.dropna(subset=['score'])\n",
    "        tprice = tprice.sort_values(by='score', ascending=False)\n",
    "        # select top n stocks\n",
    "        return tprice.head(self.n).index\n",
    "\n",
    "    # calculate maximum drawdown of a portfolio\n",
    "    def maxdrawdown(self, rarr):\n",
    "        marr = [rarr[0:i + 1].max() for i in np.arange(len(rarr))]\n",
    "        ddarr = rarr / marr - 1\n",
    "        return (ddarr.min())\n",
    "\n",
    "    # calculate Sharpe ratio of a portfolio\n",
    "    def sharpe_ratio(self, rarr, mark):\n",
    "        return ((rarr.loc[:, mark].mean() - 0.0001) / rarr.loc[:, mark].std())\n",
    "\n",
    "    # backtest function\n",
    "    def backtest(self):\n",
    "        # get all market trading days\n",
    "        tradedates = self.gettradedate()\n",
    "        # get all trade days for our portfolio\n",
    "        orderdates = pd.Series(self.dfScore.index.get_level_values(0).unique())\n",
    "        orderdates = orderdates[np.arange(len(orderdates)) % self.freq == 0]\n",
    "        # get portfolio traadelist\n",
    "        tradelist = {t: self.gettradestock(t) for t in orderdates}\n",
    "        # initialize netvalue DataFrame()\n",
    "        netvalue = pd.DataFrame(index=tradedates,\n",
    "                                columns=['netvalue', 'benchmark', 'return',\n",
    "                                         'benchmark return', 'excess return'])\n",
    "        netvalue.index.name = 'date'\n",
    "        \n",
    "        for i, idate in enumerate(tradedates):\n",
    "            if i == 0:\n",
    "                netvalue.loc[idate, 'netvalue'] = 1 * (1 - self.fee / 2)\n",
    "            else:\n",
    "                # get current portfolio\n",
    "                lasttradedate = orderdates[orderdates < idate].max()\n",
    "                holdings = tradelist[lasttradedate]\n",
    "                # calculate daily return\n",
    "                if idate in orderdates:\n",
    "                    netvalue.loc[idate, 'netvalue'] = netvalue.loc[lasttradedate, 'netvalue'] * \\\n",
    "                                                      (self.price_matrix.loc[idate, holdings] / \\\n",
    "                                                       self.price_matrix.loc[lasttradedate, holdings]).mean() * (\n",
    "                                                              1 - self.fee)\n",
    "                else:\n",
    "                    netvalue.loc[idate, 'netvalue'] = netvalue.loc[lasttradedate, 'netvalue'] * \\\n",
    "                                                      (self.price_matrix.loc[idate, holdings] / \\\n",
    "                                                       self.price_matrix.loc[lasttradedate, holdings]).mean()\n",
    "            # get benchmark performance\n",
    "            netvalue.loc[idate, 'benchmark'] = self.getindex(idate)\n",
    "            # calculate return and excess return\n",
    "            netvalue['return'] = netvalue.netvalue / netvalue.netvalue.shift(1).fillna(method='bfill') - 1\n",
    "            netvalue['benchmark return'] = netvalue['benchmark'] / netvalue['benchmark'] \\\n",
    "                .shift(1).fillna(method='bfill') - 1\n",
    "            netvalue['excess return'] = netvalue['return'] - netvalue['benchmark return']\n",
    "\n",
    "        self.netvalue = netvalue\n",
    "        return (self.netvalue)\n",
    "    \n",
    "    # portfolio evaluation\n",
    "    def evaluation(self):\n",
    "        if not hasattr(self, 'netvalue'):\n",
    "            self.backtest()\n",
    "\n",
    "        res = pd.DataFrame(columns=['yearMonth', 'return', 'annualReturn',\n",
    "                                    'maxDrawDown', 'Sharpe', 'winRate',\n",
    "                                    'excessReturn', 'annualExcessReturn'])\n",
    "\n",
    "        alpha = self.netvalue.copy(deep=True)\n",
    "        alpha.loc[:, 'year'] = alpha.index.year\n",
    "        alpha.loc[:, 'yearmonth'] = alpha.index.year*100+alpha.index.month\n",
    "        alpha['fullreturn'] = alpha.netvalue / alpha.netvalue.iloc[0] - 1\n",
    "        alpha['fullexcessreturn'] = alpha.netvalue / alpha.netvalue.iloc[0] - \\\n",
    "                                    alpha.benchmark / alpha.benchmark.iloc[0]\n",
    "\n",
    "        yearmonth = alpha.loc[:, 'yearmonth'].unique()\n",
    "        for ni in np.arange(len(yearmonth)):\n",
    "            data = alpha[alpha.yearmonth == yearmonth[ni]].sort_values(by='date',ascending=True)\n",
    "            wincount = len(data[data['excess return'] > 0])\n",
    "\n",
    "            if len(data) <= 1:\n",
    "                break\n",
    "            res.loc[ni, 'yearMonth'] = str(yearmonth[ni])\n",
    "            res.loc[ni, 'return'] = (1 + data['return']).product() - 1\n",
    "            res.loc[ni, 'annualReturn'] = res.loc[ni, 'return'] * 12\n",
    "            res.loc[ni, 'maxDrawDown'] = self.maxdrawdown(data.fullreturn + 1)\n",
    "            res.loc[ni, 'Sharpe'] = self.sharpe_ratio(data, 'return') * np.sqrt(252)\n",
    "            res.loc[ni, 'winRate'] = wincount / len(data)\n",
    "            res.loc[ni, 'excessReturn'] = (1 + data.iloc[-1, :]['fullexcessreturn']) / (1 + data.iloc[0, :]['fullexcessreturn']) - 1\n",
    "            res.loc[ni, 'annualExcessReturn'] = res.loc[ni, 'excessReturn'] * 12\n",
    "\n",
    "        res.loc[ni + 1, 'yearMonth'] = 'Total'\n",
    "        res.loc[ni + 1, 'return'] = (1 + alpha.iloc[-1, :]['fullreturn']) / (1 + alpha.iloc[0, :]['fullreturn']) - 1\n",
    "        res.loc[ni + 1, 'annualReturn'] = res.loc[ni + 1, 'return'] * 12 / len(yearmonth)\n",
    "        res.loc[ni + 1, 'maxDrawDown'] = self.maxdrawdown(alpha.fullreturn + 1)\n",
    "        res.loc[ni + 1, 'Sharpe'] = self.sharpe_ratio(alpha, 'return') * np.sqrt(252)\n",
    "        res.loc[ni + 1, 'winRate'] = len(alpha[alpha['excess return'] > 0]) / len(alpha)\n",
    "        res.loc[ni + 1, 'excessReturn'] = (1 + alpha.iloc[-1, :]['fullexcessreturn']) / (1 + alpha.iloc[0, :]['fullexcessreturn']) - 1\n",
    "        res.loc[ni + 1, 'annualExcessReturn'] = res.loc[ni + 1, 'excessReturn'] * 12 / len(yearmonth)\n",
    "        self.valuation = res\n",
    "        return (self.valuation)\n",
    "    \n",
    "    # plot portfolio and benchmark performance\n",
    "    def plot(self):\n",
    "        if not hasattr(self, 'netvalue'):\n",
    "            self.backtest()\n",
    "        netvalue = self.netvalue\n",
    "        netvalue[['netvalue','benchmark']].plot(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">2020-01-16</th>\n",
       "      <th>000001.SZ</th>\n",
       "      <td>0.0992907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000002.SZ</th>\n",
       "      <td>0.13436647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000004.SZ</th>\n",
       "      <td>0.2613816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000005.SZ</th>\n",
       "      <td>-0.06202596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000006.SZ</th>\n",
       "      <td>-0.034159854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000007.SZ</th>\n",
       "      <td>0.064261585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000008.SZ</th>\n",
       "      <td>0.046001095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000009.SZ</th>\n",
       "      <td>-0.058375183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000011.SZ</th>\n",
       "      <td>-0.010630406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000012.SZ</th>\n",
       "      <td>-0.04287688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             score\n",
       "date       stock                  \n",
       "2020-01-16 000001.SZ     0.0992907\n",
       "           000002.SZ    0.13436647\n",
       "           000004.SZ     0.2613816\n",
       "           000005.SZ   -0.06202596\n",
       "           000006.SZ  -0.034159854\n",
       "           000007.SZ   0.064261585\n",
       "           000008.SZ   0.046001095\n",
       "           000009.SZ  -0.058375183\n",
       "           000011.SZ  -0.010630406\n",
       "           000012.SZ   -0.04287688"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict = pd.read_parquet(\"predictions/%s-%s.parquet\" % (begt, endt))\n",
    "df_predict.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline performance:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearMonth</th>\n",
       "      <th>return</th>\n",
       "      <th>annualReturn</th>\n",
       "      <th>maxDrawDown</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>winRate</th>\n",
       "      <th>excessReturn</th>\n",
       "      <th>annualExcessReturn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202001</td>\n",
       "      <td>-0.046604</td>\n",
       "      <td>-0.559254</td>\n",
       "      <td>-0.046604</td>\n",
       "      <td>-15.315219</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.01487</td>\n",
       "      <td>-0.178444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202002</td>\n",
       "      <td>0.051131</td>\n",
       "      <td>0.613571</td>\n",
       "      <td>-0.053999</td>\n",
       "      <td>1.447644</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.104556</td>\n",
       "      <td>1.25467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202003</td>\n",
       "      <td>-0.097726</td>\n",
       "      <td>-1.172713</td>\n",
       "      <td>-0.149902</td>\n",
       "      <td>-2.991332</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.037124</td>\n",
       "      <td>-0.445485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202004</td>\n",
       "      <td>-0.00638</td>\n",
       "      <td>-0.076566</td>\n",
       "      <td>-0.067236</td>\n",
       "      <td>-0.379082</td>\n",
       "      <td>0.47619</td>\n",
       "      <td>-0.042573</td>\n",
       "      <td>-0.510874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202005</td>\n",
       "      <td>0.048727</td>\n",
       "      <td>0.584723</td>\n",
       "      <td>-0.044966</td>\n",
       "      <td>4.1436</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.039719</td>\n",
       "      <td>0.476623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>202006</td>\n",
       "      <td>0.116548</td>\n",
       "      <td>1.398571</td>\n",
       "      <td>-0.011351</td>\n",
       "      <td>10.43633</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.063216</td>\n",
       "      <td>0.75859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>202007</td>\n",
       "      <td>0.153756</td>\n",
       "      <td>1.845073</td>\n",
       "      <td>-0.06958</td>\n",
       "      <td>5.656122</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.059979</td>\n",
       "      <td>0.719745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>202008</td>\n",
       "      <td>0.048246</td>\n",
       "      <td>0.578948</td>\n",
       "      <td>-0.058144</td>\n",
       "      <td>2.181778</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.017945</td>\n",
       "      <td>0.215345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>202009</td>\n",
       "      <td>-0.067682</td>\n",
       "      <td>-0.812185</td>\n",
       "      <td>-0.092533</td>\n",
       "      <td>-4.763138</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>-0.021304</td>\n",
       "      <td>-0.255646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>202010</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>0.22102</td>\n",
       "      <td>-0.06702</td>\n",
       "      <td>1.235858</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.036697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>202011</td>\n",
       "      <td>-0.042985</td>\n",
       "      <td>-0.51582</td>\n",
       "      <td>-0.049109</td>\n",
       "      <td>-3.601519</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.076658</td>\n",
       "      <td>-0.919902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>202012</td>\n",
       "      <td>-0.025818</td>\n",
       "      <td>-0.309811</td>\n",
       "      <td>-0.045919</td>\n",
       "      <td>-3.020179</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.009915</td>\n",
       "      <td>-0.118982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Total</td>\n",
       "      <td>0.126301</td>\n",
       "      <td>0.126301</td>\n",
       "      <td>-0.165017</td>\n",
       "      <td>0.533388</td>\n",
       "      <td>0.558442</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.027099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   yearMonth    return annualReturn maxDrawDown     Sharpe   winRate  \\\n",
       "0     202001 -0.046604    -0.559254   -0.046604 -15.315219  0.333333   \n",
       "1     202002  0.051131     0.613571   -0.053999   1.447644       0.7   \n",
       "2     202003 -0.097726    -1.172713   -0.149902  -2.991332       0.5   \n",
       "3     202004  -0.00638    -0.076566   -0.067236  -0.379082   0.47619   \n",
       "4     202005  0.048727     0.584723   -0.044966     4.1436  0.611111   \n",
       "5     202006  0.116548     1.398571   -0.011351   10.43633      0.65   \n",
       "6     202007  0.153756     1.845073    -0.06958   5.656122  0.608696   \n",
       "7     202008  0.048246     0.578948   -0.058144   2.181778  0.714286   \n",
       "8     202009 -0.067682    -0.812185   -0.092533  -4.763138  0.590909   \n",
       "9     202010  0.018418      0.22102    -0.06702   1.235858     0.625   \n",
       "10    202011 -0.042985     -0.51582   -0.049109  -3.601519  0.333333   \n",
       "11    202012 -0.025818    -0.309811   -0.045919  -3.020179  0.428571   \n",
       "12     Total  0.126301     0.126301   -0.165017   0.533388  0.558442   \n",
       "\n",
       "   excessReturn annualExcessReturn  \n",
       "0      -0.01487          -0.178444  \n",
       "1      0.104556            1.25467  \n",
       "2     -0.037124          -0.445485  \n",
       "3     -0.042573          -0.510874  \n",
       "4      0.039719           0.476623  \n",
       "5      0.063216            0.75859  \n",
       "6      0.059979           0.719745  \n",
       "7      0.017945           0.215345  \n",
       "8     -0.021304          -0.255646  \n",
       "9      0.003058           0.036697  \n",
       "10    -0.076658          -0.919902  \n",
       "11    -0.009915          -0.118982  \n",
       "12     0.027099           0.027099  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bt_baseline = BackTest(df_predict, n=50, freq=10)\n",
    "print (\"Baseline performance:\")\n",
    "display(bt_baseline.evaluation())\n",
    "bt_baseline.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It can be observed that the baseline model perform just as good as our benchmark index 000001.SH.**\n",
    "\n",
    "Now let's see what we can do adding the mystery of CNN structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is assumed that the past trading information heralds future return. The two-dimensional feature of CNN is desirable for this task because data pictures contain different kinds of variables and their time variation. However, traditional CNN, which recognizes local pattern of data input, has troubles in developing models due to its sensitivity to the arrangement of data input. How variables are compiled changes the local patterns, resulting in different ensuing features in modelling. To avoid this drawback, we manually program to extract commonly-used features from data pictures. The following is our list of custom functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> \n",
       "table td, table th, table tr {text-align:left !important;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style> \n",
    "table td, table th, table tr {text-align:left !important;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{Table 1. List of Functions and Their Description}$$\n",
    "\n",
    "Function | Description | Mapping Example\n",
    "-|:- | -:\n",
    "ts_corr|compute the correlations between rows|(n,9,30)->(n,36,3)\n",
    "ts_cov|compute the covariance between rows|(n,9,30)->(n,36,3)\n",
    "ts_mean|compute the mean of blocks in each row|(n,9,30)->(n,9,3)\n",
    "ts_stddev|compute the standard deviation of blocks in each row|(n,9,30)->(n,9,3)\n",
    "ts_zscore|compute the zscore (mean over std.dev.) of blocks in each row|(n,9,30)->(n,9,3)\n",
    "ts_return|compute the return of blocks in each row|(n,9,30)->(n,9,3)\n",
    "ts_decaylinear|compute the weighted average (with decaying weights) of blocks in each row|(n,9,30)->(n,9,3)\n",
    "\n",
    "Note: The parameters are mutable. By default, the span of function and stride are 10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions in Table 1 can be divided into two types. The first type measures the relationship between rows. The second type computes the statistics of each rows.\n",
    "\n",
    "Type One: ts_corr, ts_cov\n",
    "\n",
    "Type Two: ts_mean, ts_stddev, ts_zscore, ts_return, ts_decaylinear\n",
    "\n",
    "<img src=\"https://z3.ax1x.com/2021/07/23/WsQEVA.png\" style=\"\" width=\"600\">\n",
    "\n",
    "<img src=\"https://z3.ax1x.com/2021/07/23/WsQNGV.png\" style=\"\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Batch Normalization:**\n",
    "\n",
    "$$\\text{Batch Mean : } \\mu = \\frac{1}{m} \\sum_{l=0}^m Z^{l(i)}$$\n",
    "\n",
    "$$\\text{Batch Std. Dev. : } \\sigma^2 = \\frac{1}{m} \\sum_{i=0}^m (Z^{l(i)}-\\mu)^2$$\n",
    "\n",
    "$$\\text{Normalized Result : } \\hat Z^{l(i)} = (Z^{l(i)} - \\mu)/\\sigma$$\n",
    "\n",
    "where $Z^{l}$ denotes the layer and $Z^{l(i)}$ denotes the elements in the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*List of Pooling Layer**\n",
    "\n",
    "$$\\text{Table 2. List of Pooling Functions and Their Description}$$\n",
    "\n",
    "Function | Description | Mapping Example\n",
    "-|- | -\n",
    "mean|compute the mean of blocks in each row|(n,k,3)->(n,k)\n",
    "max|compute the max of blocks in each row|(n,k,3)->(n,k)\n",
    "min|compute the min of blocks in each row|(n,k,3)->(n,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline Structure**\n",
    "\n",
    "The realization of figure 2 is more like a combined pipeline function described below.\n",
    "\n",
    "<img src=\"https://z3.ax1x.com/2021/07/23/Wrg3RK.png\" style=\"\" width=\"600\">\n",
    "\n",
    "<b>`All the python code is reported in feature_extraction_file.py in the attachment.`</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 430.04it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 601.59it/s]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1504.59it/s]\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 501.59it/s]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1504.95it/s]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1502.98it/s]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1504.95it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 175.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter number 0 is starting\n",
      "pooling number 0 is starting\n",
      "pooling number 1 is starting\n",
      "pooling number 2 is starting\n",
      "filter number 0 finished\n",
      "\n",
      "\n",
      "filter number 1 is starting\n",
      "pooling number 0 is starting\n",
      "pooling number 1 is starting\n",
      "pooling number 2 is starting\n",
      "filter number 1 finished\n",
      "\n",
      "\n",
      "filter number 2 is starting\n",
      "pooling number 0 is starting\n",
      "pooling number 1 is starting\n",
      "pooling number 2 is starting\n",
      "filter number 2 finished\n",
      "\n",
      "\n",
      "filter number 3 is starting\n",
      "pooling number 0 is starting\n",
      "pooling number 1 is starting\n",
      "pooling number 2 is starting\n",
      "filter number 3 finished\n",
      "\n",
      "\n",
      "filter number 4 is starting\n",
      "pooling number 0 is starting\n",
      "pooling number 1 is starting\n",
      "pooling number 2 is starting\n",
      "filter number 4 finished\n",
      "\n",
      "\n",
      "filter number 5 is starting\n",
      "pooling number 0 is starting\n",
      "pooling number 1 is starting\n",
      "pooling number 2 is starting\n",
      "filter number 5 finished\n",
      "\n",
      "\n",
      "filter number 6 is starting\n",
      "pooling number 0 is starting\n",
      "pooling number 1 is starting\n",
      "pooling number 2 is starting\n",
      "filter number 6 finished\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 351)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import feature_extraction_file as file\n",
    "\n",
    "result=file.pipeline(np.array(X[0:2]))\n",
    "\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part V: Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Structure\n",
    "The network architecture is feature input layers + fully connected dense layer. The model structure of Stock-Selector-Alpha is shown below. \n",
    "\n",
    "After feature engineering layers, StockSelector-Alpha will flatten all features, disgarding the temporal information. \n",
    "\n",
    "The flattened features are then fed into a dense layer with 64 units. The number of neurons in the hidden layer is not restrained, but the literature recommends setting it at an even power of 2, such as 64, 32, etc. for accelerating GPU/CPU calculations (Vanhoucke and Senior, 2011), and hence the 64 units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"model.png\" style=\"\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Configuration\n",
    "The activation function for the dense layer is the linear rectified unit (ReLU), whose derivative is easy to compute.\n",
    "\n",
    "The optimizer is a SGD algorithm called Adam, which is an extended version of SGD proposed by Kingma and Ba (2017).\n",
    "\n",
    "The learning rate is 0.002\n",
    "\n",
    "\n",
    "\n",
    "#### Regularization\n",
    "Neural networks are extremely easy to overfit and regularization is indispensable.\n",
    "\n",
    "We use three regularization methods from the literature to mitigate overfitting - batch normalization, early stopping, and dropout.\n",
    "\n",
    "##### Early Stopping\n",
    "Early stopping is that we examine model performances on the validation set and stop training whenever we observe that model performances on the validation set stop improving. Typically, models will stop improving on the validation set earlier than on the training set, so it is named \"Early Stopping\".\n",
    "\n",
    "##### Batch Normalization\n",
    "The rationale behind batch normalization is that Adam randomly selects a batch of observations and only uses that batch of data for gradient updating in every optimization round, because computing gradients for all observations is costly and unnecessary. Hence, sample draws may have heterogeneous distributions.  In order to sterilize the impact of heterogeneous random draws, we normalize the random batch after the input layer and between each fully connected hidden layer. The specific operations are to first subtract the mean and then divide the square root of batch variance.\n",
    "\n",
    "##### Dropout\n",
    "Dropout is a technique that literally “drop out” a certain portion of neurons. Dropout is a potent regularization method and has proved its value in computer vision. This can prevent the networks from getting too convoluted by randomly setting a specific proportion of neurons in each layer to 0. The dropout rate in the input layer is 20%, and in the hidden layer is 50%. It needs to be particularly emphasized that we enlarge the number of neurons accordingly. we adjust the number of neurons to be the original neuron number dividing the dropout rate. For example, if the dropout rate is 50% and the original number of neurons is 32, then the new number of neurons is 52/0.5 = 64.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for the CNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockSelectorAlpha:\n",
    "    # StockSelector Alpha\n",
    "    # Feature Extraction Layer + Dense Layer\n",
    "\n",
    "    def __init__(self, name, config, fit_config):\n",
    "        self.name = name\n",
    "        self.config = config\n",
    "        self.fit_config = fit_config\n",
    "\n",
    "        tf.random.set_seed(1)\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.Input(shape=(351,)),\n",
    "            tf.keras.layers.Dropout(rate=0.2),  # drop out 20% of the input\n",
    "            tf.keras.layers.BatchNormalization(),  # normalize data\n",
    "\n",
    "            tf.keras.layers.Dense(units=64, activation='relu',\n",
    "                                  kernel_initializer=tf.keras.initializers.TruncatedNormal()),\n",
    "            tf.keras.layers.Dropout(rate=0.5),  # drop out 50% of the neurons\n",
    "            tf.keras.layers.BatchNormalization(),  # normalize data\n",
    "            tf.keras.layers.Dense(units=1, kernel_initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        ])\n",
    "        earlystop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=33,\n",
    "                                                     verbose=0, mode=\"min\", baseline=None,\n",
    "                                                     restore_best_weights=True)\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(config['model_path'], monitor='val_loss', verbose=0,\n",
    "                                                        save_best_only=True, mode='min')\n",
    "        self.cb_list = [earlystop, checkpoint]\n",
    "        opt = tf.keras.optimizers.Adam(lr=self.config['learning_rate'], clipvalue=0.5)\n",
    "        self.model.compile(loss=self.config['loss'], optimizer=opt, metrics=self.config['metrics'])\n",
    "\n",
    "    def fit(self, x, y, validation_data):\n",
    "        self.model.fit(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            validation_data=(validation_data),\n",
    "            callbacks=self.cb_list,\n",
    "            **self.fit_config\n",
    "        )\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        return y_pred\n",
    "\n",
    "    def save(self, path, name):\n",
    "        if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "        self.model.save(path + name + '.h5')\n",
    "        pd.DataFrame(self.model.history.history).to_csv(path + name + '_train_history.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for configuration, training and predicting:\n",
    "\n",
    "25% of the in-sample data are used for validation and early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "config = {\n",
    "    'model_path': Path('models'),\n",
    "    'feat_num': 351,\n",
    "    'learning_rate': 0.002,\n",
    "    'loss': 'mse',\n",
    "    'metrics': 'mse',\n",
    "}\n",
    "\n",
    "fit_config = {\n",
    "    'batch_size': 2560,\n",
    "    'epochs': 10000,\n",
    "}\n",
    "\n",
    "# load and prepare data for training and validating\n",
    "dir_ = Path(\"data\")\n",
    "with open(dir_ / 'x_train.pkl', 'rb') as f:\n",
    "    x_train = pickle.load(f)\n",
    "with open(dir_ / \"y_train.pkl\", \"rb\") as f:\n",
    "    y_train = pickle.load(f)\n",
    "\n",
    "_train_data = pd.DataFrame(\n",
    "    np.concatenate((x_train, y_train.reshape(-1, 1)), axis=1)).dropna()  # drop na values in the X and Y\n",
    "_train_data = _train_data.sample(frac=1, random_state=1)\n",
    "thr = round(_train_data.shape[0] * 0.75)\n",
    "train_data = _train_data.iloc[:thr, :]\n",
    "x_train2 = train_data.iloc[:, :351]\n",
    "y_train2 = train_data.iloc[:, 351]\n",
    "\n",
    "val_data = _train_data.iloc[thr:, :]\n",
    "x_val, y_val = val_data.iloc[:, :351], val_data.iloc[:, 351]\n",
    "\n",
    "# %%\n",
    "# Train model\n",
    "date_str = datetime.datetime.today().strftime(\"%Y%m%d-%H%M\")\n",
    "selector_to_train = StockSelectorAlpha('stock_selector_on_%s' % date_str, config, fit_config)\n",
    "selector_to_train.fit(x_train2, y_train2, validation_data=(x_val, y_val))\n",
    "selector_to_train.save('models/', selector_to_train.name)\n",
    "\n",
    "# %%\n",
    "# Make predictions\n",
    "with open(dir_ / 'x_pred.pkl', 'rb') as f:\n",
    "    x_pred = pickle.load(f)\n",
    "with open(dir_ / 'id_pred.pkl', 'rb') as f:\n",
    "    id_pred = pickle.load(f)\n",
    "pred_data = pd.DataFrame(np.concatenate((x_pred, id_pred), axis=1)).dropna()\n",
    "x_pred2 = pred_data.iloc[:, :351]\n",
    "id_pred2 = pred_data.iloc[:, 351:]\n",
    "\n",
    "selector_to_predict = tf.keras.models.load_model(os.path.join('models', 'stock_selector_on_20210722-2311.h5'))\n",
    "y_pred = selector_to_predict.predict(x_pred2)\n",
    "df_pred = pd.DataFrame(np.concatenate((id_pred2, y_pred), axis=1), columns=['stockid', 'date', 'score']).set_index(\n",
    "    ['stockid', 'date']).swaplevel().sort_index()\n",
    "df_pred.to_parquet('prediction_20200701_20201231.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare: LSTM Model\n",
    "The CNN version forgoes the temporal informaiton embeded in the feature map. We gauge that there might be great potential in exploiting the information carried in the sequence.\n",
    "\n",
    "Therefore, the beta version use a recurrent neural network - LSTM to leverage temporal sequnces.\n",
    "\n",
    "Different from the Dense layers, the input shape of the LSTM network is (observations, time, features). \n",
    "\n",
    "We don't do any feature engineering. Instead, we directly input the data picture, whose dimension is time*features, to the LSTM layers. \n",
    "\n",
    "The input features are price and volume features including open, high, low, close, turnver, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"LSTM.png\" style=\"\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for the LSTM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model:\n",
    "    # StockSelector Beta\n",
    "    # LSTM Layer + Dense Layer\n",
    "\n",
    "    def __init__(self, name, config, fit_config):\n",
    "        self.name = \"lstm_\" + name\n",
    "        self.config = config\n",
    "        self.fit_config = fit_config\n",
    "\n",
    "        tf.random.set_seed(1)\n",
    "        self.model = tf.keras.Sequential([\n",
    "            tf.keras.Input(shape=(9, 30)),\n",
    "            tf.keras.layers.Dropout(rate=0.2),    # drop out 20% of the input\n",
    "            tf.keras.layers.BatchNormalization(),  # normalize data\n",
    "            # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "            tf.keras.layers.LSTM(64, return_sequences=False, recurrent_dropout=0.5),   # drop out 50% of the input\n",
    "            # Shape => [batch, time, features]\n",
    "            tf.keras.layers.Dense(units=64, activation='relu',\n",
    "                                  kernel_initializer=tf.keras.initializers.TruncatedNormal()),\n",
    "            tf.keras.layers.Dense(units=1, kernel_initializer=tf.keras.initializers.TruncatedNormal())\n",
    "        ])\n",
    "        earlystop = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=33,\n",
    "                                                     verbose=0, mode=\"min\", baseline=None,\n",
    "                                                     restore_best_weights=True)\n",
    "        checkpoint = tf.keras.callbacks.ModelCheckpoint(config['model_path'], monitor='val_loss', verbose=0,\n",
    "                                                        save_best_only=True, mode='min')\n",
    "        self.cb_list = [earlystop, checkpoint]\n",
    "        opt = tf.keras.optimizers.Adam(lr=self.config['learning_rate'], clipvalue=0.5)\n",
    "\n",
    "        if len(tf.config.experimental.list_physical_devices('GPU')) == 0:\n",
    "            self.GPU = False\n",
    "            self.model.compile(loss=self.config['loss'], optimizer=opt, metrics=self.config['metrics'])\n",
    "        else:\n",
    "            self.GPU = True\n",
    "            self.model.compile(loss=self.config['loss'], optimizer=opt, metrics=self.config['metrics'])\n",
    "\n",
    "    def fit(self, x, y, validation_data=None):\n",
    "        self.model.fit(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            validation_data=(validation_data),\n",
    "            callbacks=self.cb_list,\n",
    "            **self.fit_config\n",
    "        )\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        y_pred = self.model.predict(x_test)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
